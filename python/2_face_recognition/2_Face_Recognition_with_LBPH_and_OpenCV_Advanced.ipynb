{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16991965-4864-4434-a14f-8b8f0ef30ea1",
   "metadata": {},
   "source": [
    "## LBPH\n",
    "\n",
    "Local Binary Patterns Histograms\n",
    "\n",
    "1. Radius\n",
    "   - 이 값을 증가시키면, 엣지를 찾는데 어려움을 겪습니다.\n",
    "   - 하지만, 더 많은 패턴을 찾을 수 있습니다.\n",
    "2. Neighbors\n",
    "    - 실제로 연산하게 되는 양을 의미합니다.\n",
    "    - 이 값이 늘어날수록, 연산 시간이 길어집니다.\n",
    "3. grid_x & grid_y\n",
    "    - 셀이 많은 수록, 히스토그램의 수가 늘고 패턴을 찾기 쉬워집니다.\n",
    "    - 셀이 적을 수록, 히스토그램의 수가 적고 패턴을 찾기 어렵지만 연산 속도가 빨라집니다.\n",
    "4. threshold\n",
    "    - 감지의 신뢰도를 의미하며, 높을 수록 안면 인식의 품질이 좋아집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b4ee956-a044-4ec5-a0fc-6f2921a3ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f307d5-b4e0-4086-8267-2155fde6059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBPH Rrecognizer\n",
    "lbph_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
    "lbph_classifier.read('./lbph_classifier.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "673cd249-39fd-4bdd-8371-50eef92d255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [os.path.join('yalefaces/test', f) for f in os.listdir('yalefaces/test')]\n",
    "paths = [f.replace('\\\\', '/') for f in paths]\n",
    "\n",
    "predictions = []\n",
    "expected_outputs = []\n",
    "\n",
    "for path in paths:\n",
    "    \n",
    "    image = Image.open(path).convert('L')\n",
    "    image_np = np.array(image, 'uint8')\n",
    "    \n",
    "    prediction, _ = lbph_classifier.predict(image_np)\n",
    "    expected_output = int(os.path.split(path)[1][7:9])\n",
    "    \n",
    "    predictions.append(prediction)\n",
    "    expected_outputs.append(expected_output)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "expected_outputs = np.array(expected_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "942b919d-5261-4516-b352-c9f8054802cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(expected_outputs, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01de8f8-2351-447e-b4db-ed56a2529922",
   "metadata": {},
   "source": [
    "### 튜닝된 얼굴 인식\n",
    "\n",
    "1. threshold = 1.7976931348623157e+308\n",
    "2. radius = 1\n",
    "3. neighbors = 8\n",
    "4. grid_x = 8\n",
    "5. grid_y = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a9b5f00-b506-40f0-b249-9268a4304b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data():\n",
    "    paths = [os.path.join('yalefaces/train', f) for f in os.listdir('yalefaces/train')]\n",
    "    paths = [f.replace('\\\\', '/') for f in paths]\n",
    "    \n",
    "    faces = []\n",
    "    ids = []\n",
    "    \n",
    "    for path in paths:\n",
    "        image = Image.open(path).convert('L') # 'L'은 Single Channel을 의미합니다.\n",
    "        image_np = np.array(image, 'uint8')\n",
    "        \n",
    "        id = int(os.path.split(path)[1][7:9])\n",
    "        \n",
    "        ids.append(id)\n",
    "        faces.append(image_np)\n",
    "    \n",
    "    return np.array(ids), faces\n",
    "ids, faces = get_image_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dc62d0d-7a15-449f-afb7-8efa3aa10734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBPH Rrecognizer\n",
    "tunning_lbph_classifier = cv2.face.LBPHFaceRecognizer_create(\n",
    "    radius = 1,\n",
    "    neighbors = 8,\n",
    "    grid_x = 8,\n",
    "    grid_y = 8\n",
    ")\n",
    "tunning_lbph_classifier.train(src=faces, labels=ids)\n",
    "tunning_lbph_classifier.write('lbph_classifier_tunning.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f67c4ab3-2577-452b-ac05-fda3db163da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [os.path.join('yalefaces/test', f) for f in os.listdir('yalefaces/test')]\n",
    "paths = [f.replace('\\\\', '/') for f in paths]\n",
    "\n",
    "predictions = []\n",
    "expected_outputs = []\n",
    "\n",
    "for path in paths:\n",
    "    \n",
    "    image = Image.open(path).convert('L')\n",
    "    image_np = np.array(image, 'uint8')\n",
    "    \n",
    "    prediction, _ = tunning_lbph_classifier.predict(image_np)\n",
    "    expected_output = int(os.path.split(path)[1][7:9])\n",
    "    \n",
    "    predictions.append(prediction)\n",
    "    expected_outputs.append(expected_output)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "expected_outputs = np.array(expected_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ca689c9-b7b9-424c-8499-cf158284cd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6333333333333333"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(expected_outputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054d4ae-69b1-4d8b-97b5-2678a01969a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
